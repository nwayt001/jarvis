#!/usr/bin/env python3
"""
Test script for Mac-optimized Chatterbox TTS
Verifies MPS acceleration and voice synthesis
"""
import torch
import torchaudio as ta
import os
import time

def test_mac_tts():
    print("üß™ Testing Chatterbox TTS on Mac")
    print("=" * 50)
    
    # Check device availability
    print("\n1Ô∏è‚É£ Checking device support...")
    if torch.backends.mps.is_available():
        device = "mps"
        print("   ‚úÖ Apple Metal Performance Shaders (MPS) available!")
        print("   üöÄ Using hardware acceleration")
    else:
        device = "cpu"
        print("   ‚ÑπÔ∏è  MPS not available, using CPU")
    
    # Setup device mapping for model loading
    print("\n2Ô∏è‚É£ Setting up device mapping...")
    map_location = torch.device(device)
    
    torch_load_original = torch.load
    def patched_torch_load(*args, **kwargs):
        if 'map_location' not in kwargs:
            kwargs['map_location'] = map_location
        return torch_load_original(*args, **kwargs)
    
    torch.load = patched_torch_load
    print("   ‚úÖ Device mapping configured")
    
    # Load model
    print("\n3Ô∏è‚É£ Loading Chatterbox model...")
    start_time = time.time()
    
    try:
        from chatterbox.tts import ChatterboxTTS
        model = ChatterboxTTS.from_pretrained(device=device)
        load_time = time.time() - start_time
        print(f"   ‚úÖ Model loaded in {load_time:.2f} seconds")
        print(f"   üìç Running on: {device}")
    except Exception as e:
        print(f"   ‚ùå Failed to load model: {e}")
        return
    
    # Check for JARVIS voice
    print("\n4Ô∏è‚É£ Checking for JARVIS voice sample...")
    voice_paths = [
        "audio_library/jarvis_sample.wav",
        "audio_library/jarvis_sample.aif",
        "jarvis_sample.wav",
        "jarvis_sample.aif"
    ]
    
    jarvis_voice = None
    for path in voice_paths:
        if os.path.exists(path):
            jarvis_voice = path
            print(f"   ‚úÖ Found JARVIS voice at: {path}")
            break
    else:
        print("   ‚ö†Ô∏è  JARVIS voice not found, using default voice")
    
    # Test generation
    print("\n5Ô∏è‚É£ Testing speech synthesis...")
    test_text = "Good evening, Sir. All systems are now online. The Mac optimization is working perfectly."
    
    print(f"   Text: '{test_text}'")
    print("   Generating audio...")
    
    start_time = time.time()
    
    try:
        if jarvis_voice:
            wav = model.generate(
                test_text,
                audio_prompt_path=jarvis_voice,
                exaggeration=0.3,
                cfg_weight=0.5
            )
        else:
            wav = model.generate(
                test_text,
                exaggeration=0.3,
                cfg_weight=0.5
            )
        
        gen_time = time.time() - start_time
        
        # Save the output
        output_file = "test_mac_output.wav"
        ta.save(output_file, wav, model.sr)
        
        print(f"   ‚úÖ Audio generated in {gen_time:.2f} seconds")
        print(f"   üíæ Saved to: {output_file}")
        print(f"   üéµ Sample rate: {model.sr} Hz")
        print(f"   üìè Duration: {wav.shape[1] / model.sr:.2f} seconds")
        
        # Performance metrics
        rtf = gen_time / (wav.shape[1] / model.sr)
        print(f"   ‚ö° Real-time factor: {rtf:.2f}x (lower is better)")
        
        if rtf < 1.0:
            print("   üéâ Faster than real-time!")
        
    except Exception as e:
        print(f"   ‚ùå Generation failed: {e}")
        return
    
    # Test streaming if available
    print("\n6Ô∏è‚É£ Testing streaming capability...")
    if hasattr(model, 'generate_stream'):
        print("   ‚úÖ Streaming generation available!")
        
        try:
            chunks = 0
            first_chunk_time = None
            
            for audio_chunk, metrics in model.generate_stream(
                "Testing streaming synthesis.",
                exaggeration=0.3,
                cfg_weight=0.5
            ):
                chunks += 1
                if chunks == 1 and hasattr(metrics, 'latency_to_first_chunk'):
                    first_chunk_time = metrics.latency_to_first_chunk
            
            print(f"   üì¶ Generated {chunks} chunks")
            if first_chunk_time:
                print(f"   ‚è±Ô∏è  First chunk latency: {first_chunk_time:.3f}s")
        except Exception as e:
            print(f"   ‚ö†Ô∏è  Streaming test failed: {e}")
    else:
        print("   ‚ÑπÔ∏è  Streaming not available in this version")
    
    # Summary
    print("\n" + "=" * 50)
    print("‚úÖ TTS Test Complete!")
    print("\nRecommendations:")
    
    if device == "mps":
        print("‚Ä¢ You're using Metal acceleration - optimal for Mac! üçé")
    else:
        print("‚Ä¢ Consider upgrading to Apple Silicon for better performance")
    
    if jarvis_voice:
        print("‚Ä¢ JARVIS voice is configured correctly")
    else:
        print("‚Ä¢ Add a JARVIS voice sample for authentic speech")
    
    if rtf < 0.5:
        print("‚Ä¢ Excellent performance - very fast generation!")
    elif rtf < 1.0:
        print("‚Ä¢ Good performance - faster than real-time")
    else:
        print("‚Ä¢ Consider reducing quality settings for faster generation")
    
    print("\nTo play the test audio:")
    print(f"  afplay {output_file}")

if __name__ == "__main__":
    test_mac_tts()